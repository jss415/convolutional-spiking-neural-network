{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60FRbBZVSket"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, sampler\n",
        "from skimage.filters import gaussian\n",
        "from skimage.util import random_noise\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "from collections import defaultdict\n",
        "import noises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wPM522ISkez"
      },
      "outputs": [],
      "source": [
        "class PseudoSpikeRect(torch.autograd.Function):\n",
        "    \"\"\" Rectangular Pseudo-grad function \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, vth, grad_win, grad_amp):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input (Torch Tensor): Input tensor containing voltages of neurons in a layer\n",
        "            vth (Float): Voltage threshold for spiking \n",
        "            grad_win (Float): Window for computing pseudogradient\n",
        "            grad_amp (Float): Amplification factor for the gradients\n",
        "        \n",
        "        Returns:\n",
        "            output (Torch Tensor): Generated spikes for the input\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        #Saving variables for backward pass. \n",
        "        ctx.save_for_backward(input)\n",
        "        ctx.vth = vth\n",
        "        ctx.grad_win = grad_win\n",
        "        ctx.grad_amp = grad_amp\n",
        "        \n",
        "        #Compute output from the input.\n",
        "        output = (input > vth).float()\n",
        "        \n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            grad_output (Torch Tensor): Gradient of the output\n",
        "        \n",
        "        Returns:\n",
        "            grad (Torch Tensor): Gradient of the input\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        #Retrieving variables from forward pass.\n",
        "        input, = ctx.saved_tensors\n",
        "        vth = ctx.vth\n",
        "        grad_win = ctx.grad_win\n",
        "        grad_amp = ctx.grad_amp\n",
        "        grad_input = grad_output.clone()\n",
        "\n",
        "        #Compute the gradient of the input using rectangular pseudograd function\n",
        "        spike_pseudo_grad = torch.abs(ctx.saved_tensors[0] - vth)          \n",
        "        spike_pseudo_grad = torch.lt(spike_pseudo_grad, grad_win).float()\n",
        "        #Multiply by gradient amplifier.\n",
        "        grad = grad_amp * grad_input * spike_pseudo_grad.float()\n",
        "\n",
        "        return grad, None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oJNTGPOSke1"
      },
      "outputs": [],
      "source": [
        "class LinearIFCell(nn.Module):\n",
        "    \"\"\" Leaky Integrate-and-fire neuron layer\"\"\"\n",
        "\n",
        "    def __init__(self, psp_func, pseudo_grad_ops, param):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            psp_func (Torch Function): Pre-synaptic function\n",
        "            pseudo_grad_ops (Torch Function): Pseudo-grad function\n",
        "            param (tuple): Cell parameters (Voltage Threshold, gradient window, gradient amplitude)\n",
        "        \n",
        "        \"\"\"\n",
        "        super(LinearIFCell, self).__init__()\n",
        "        self.psp_func = psp_func\n",
        "        self.pseudo_grad_ops = pseudo_grad_ops\n",
        "        self.vdecay, self.vth, self.grad_win, self.grad_amp = param\n",
        "\n",
        "    def forward(self, input_data, state):\n",
        "        \"\"\"\n",
        "        Forward function\n",
        "        Args:\n",
        "            input_data (Tensor): input spike from pre-synaptic neurons\n",
        "            state (tuple): output spike of last timestep and voltage of last timestep\n",
        "        Returns:\n",
        "            output: output spike\n",
        "            state: updated neuron states\n",
        "        \n",
        "        \"\"\"\n",
        "        pre_spike, pre_volt = state\n",
        "        \n",
        "        #Compute the voltage from the presynaptic inputs.\n",
        "        volt = self.vdecay*pre_volt*(1-pre_spike) + self.psp_func(input_data)\n",
        "\n",
        "        #Compute the spike output by using the pseudo_grad_ops function.\n",
        "        output = self.pseudo_grad_ops(volt, self.vth, self.grad_win, self.grad_amp)\n",
        "        \n",
        "        return output, (output, volt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDgFyeVJSke3"
      },
      "outputs": [],
      "source": [
        "class SNN(nn.Module):\n",
        "    \"\"\" SNN with two convolutional layers, two pooling layers, and a single fully connected hidden layer \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, conv1_dim, conv2_dim, param_dict):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim (int): input dimension\n",
        "            output_dim (int): output dimension\n",
        "            hidden_dim (int): hidden layer dimension\n",
        "            conv1_dim (int): convolutional layer 1 output dimension\n",
        "            conv2_dim (int): convolutional layer 2 output dimension\n",
        "            param_dict (dict): neuron parameter dictionary for each LIF layer (Voltage Threshold, gradient window, gradient amplitude)\n",
        "        \n",
        "        \"\"\"\n",
        "        super(SNN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        pseudo_grad_ops = PseudoSpikeRect.apply\n",
        "        \n",
        "        # Create the convolutional and pooling layers.\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, conv1_dim, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(conv1_dim, conv2_dim, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "        self.drop_out = nn.Dropout()\n",
        "\n",
        "        #Create the hidden layer. Assume that the hidden layer neuron parameters are in param_dict['hid_layer']. Set bias=False for nn.Linear.  \n",
        "        self.hidden_cell = LinearIFCell(nn.Linear(2*2*input_dim, hidden_dim, bias=False), pseudo_grad_ops, param_dict['hid_layer'])\n",
        "        \n",
        "        \n",
        "        #Create the output layer. Output layer params are in param_dict['out_layer']. Set bias=False for nn.Linear.   \n",
        "        self.output_cell = LinearIFCell(nn.Linear(hidden_dim, output_dim, bias=False), pseudo_grad_ops, param_dict['out_layer'])\n",
        "        \n",
        "\n",
        "    def forward(self, spike_data, init_states_dict, batch_size, spike_ts):\n",
        "        \"\"\"\n",
        "        Forward function\n",
        "        Args:\n",
        "            spike_data (Tensor): spike data input (batch_size, input_dim, spike_ts)\n",
        "            init_states_dict (dict): initial states for each layer- 'hid_layer' for hidden layer; 'out_layer' for output layer. \n",
        "            batch_size (int): batch size\n",
        "            spike_ts (int): spike timesteps\n",
        "        Returns:\n",
        "            output: number of spikes of output layer\n",
        "        \n",
        "        \"\"\"\n",
        "        hidden_state, out_state = init_states_dict['hid_layer'], init_states_dict['out_layer']\n",
        "        output_list = [] #List to store the output at each timestep\n",
        "        for tt in range(spike_ts):\n",
        "            #Retrieve the input at time tt\n",
        "            input_spikes = spike_data[:,:,:,:,tt]\n",
        "\n",
        "            #Propagate through convolutional and polling layers.\n",
        "            conv_out = self.layer1(input_spikes)\n",
        "            conv_out = self.layer2(conv_out)\n",
        "            conv_out = conv_out.reshape(conv_out.size(0), -1)\n",
        "            conv_out = self.drop_out(conv_out)\n",
        "\n",
        "            #Propagate through the hidden layer\n",
        "            hidden_layer_spikes, hidden_state = self.hidden_cell.forward(conv_out, hidden_state)\n",
        "\n",
        "            #Propagate through the output layer\n",
        "            output_layer_spikes, out_state = self.output_cell.forward(hidden_layer_spikes, out_state)\n",
        "\n",
        "            #Append output spikes to output list\n",
        "            output_list.append(output_layer_spikes)\n",
        "        \n",
        "        #Sum the outputs to compute spike count for each output neuron.\n",
        "\n",
        "        output = torch.stack(output_list,0)\n",
        "        output = torch.sum(output,0)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaLIu__nSke6"
      },
      "outputs": [],
      "source": [
        "class WrapSNN(nn.Module):\n",
        "    \"\"\" Wrapper of SNN \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, conv1_dim, conv2_dim, param_dict, device):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim (int): input dimension\n",
        "            output_dim (int): output dimension\n",
        "            hidden_dim (int): hidden layer dimension\n",
        "            conv1_dim (int): convolutional layer 1 output dimension\n",
        "            conv2_dim (int): convolutional layer 2 output dimension\n",
        "            param_dict (dict): neuron parameter dictionary\n",
        "            device (device): device\n",
        "        \"\"\"\n",
        "        super(WrapSNN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.conv1_dim = conv1_dim\n",
        "        self.conv2_dim = conv2_dim\n",
        "        self.device = device\n",
        "        self.snn = SNN(input_dim, output_dim, hidden_dim, conv1_dim, conv2_dim, param_dict)\n",
        "\n",
        "    def forward(self, spike_data):\n",
        "        \"\"\"\n",
        "        Forward function\n",
        "        Args:\n",
        "            spike_data (Tensor): spike data input\n",
        "        Returns:\n",
        "            output: number of spikes of output layer\n",
        "        \"\"\"\n",
        "        batch_size = spike_data.shape[0]\n",
        "        spike_ts = spike_data.shape[-1]\n",
        "        init_states_dict = {}\n",
        "        # Hidden layer\n",
        "        hidden_volt = torch.zeros(batch_size, self.hidden_dim, device=self.device)\n",
        "        hidden_spike = torch.zeros(batch_size, self.hidden_dim, device=self.device)\n",
        "        init_states_dict['hid_layer'] = (hidden_spike, hidden_volt)\n",
        "        # Output layer\n",
        "        out_volt = torch.zeros(batch_size, self.output_dim, device=self.device)\n",
        "        out_spike = torch.zeros(batch_size, self.output_dim, device=self.device)\n",
        "        init_states_dict['out_layer'] = (out_spike, out_volt)\n",
        "        # SNN\n",
        "        output = self.snn(spike_data, init_states_dict, batch_size, spike_ts)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9HkulCeSke_"
      },
      "outputs": [],
      "source": [
        "def img_2_event_img(image, device, spike_ts):\n",
        "    \"\"\"\n",
        "    Transform image to event image\n",
        "    Args:\n",
        "        image (Tensor): image\n",
        "        device (device): device (can be either CPU or GPU)\n",
        "        spike_ts (int): spike timestep\n",
        "    Returns:\n",
        "        event_image: event image\n",
        "    \"\"\"\n",
        "    batch_size = image.shape[0]\n",
        "    channel_size = image.shape[1]\n",
        "    image_size = image.shape[2]\n",
        "    image = image.view(batch_size, channel_size, image_size, image_size, 1)\n",
        "    image.to(device)\n",
        "\n",
        "    #Create a random image of shape batch_size x channel_size x image_size x image_size x spike_ts.\n",
        "    random_image = torch.rand((batch_size, channel_size, image_size, image_size, spike_ts), device=device)\n",
        "\n",
        "    #Generate event image using image and random image\n",
        "    event_image = (image > random_image).float()\n",
        "\n",
        "    return event_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyU0jvBuxJZ4"
      },
      "outputs": [],
      "source": [
        "def get_sample_dataset(dataset, desired_labels, sample_number):\n",
        "    \"\"\"\n",
        "    Get 'sample_number' samples for each label in desired_labels\n",
        "    Args:\n",
        "        dataset (Tensor): full dataset\n",
        "        desired_lables (dict): dictionary where keys indicate the desired labels\n",
        "        sample_number (int): the number of samples to extract for each label\n",
        "    Returns:\n",
        "        sample_dataset: subset of dataset containig only the samples with the desired labels\n",
        "    \"\"\"\n",
        "    indices_for_each_label = dict()\n",
        "    sample_indices = []\n",
        "    for (i, x) in enumerate(dataset):\n",
        "      if indices_for_each_label.get(x[1], 0) < sample_number:\n",
        "        indices_for_each_label[x[1]] = indices_for_each_label.get(x[1], 0) + 1\n",
        "        sample_indices.append(i)\n",
        "    sample_dataset = torch.utils.data.Subset(dataset, sample_indices)\n",
        "    return sample_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNxGH81BSkfA"
      },
      "outputs": [],
      "source": [
        "def stbp_snn_training(network, desired_labels, spike_ts, device, batch_size=128, test_batch_size=256, epoch=100, sample_number=200, noise=None):\n",
        "    \"\"\"\n",
        "    STBP SNN training\n",
        "    Args:\n",
        "        network (SNN): STBP learning SNN\n",
        "        spike_ts (int): spike timestep\n",
        "        device (device): device\n",
        "        batch_size (int): batch size for training\n",
        "        test_batch_size (int): batch size for testing\n",
        "        epoch (int): number of epochs\n",
        "    Returns:\n",
        "        train_loss_list: list of training loss for each epoch\n",
        "        test_accuracy_list: list of test accuracy for each epoch\n",
        "    \"\"\"\n",
        "    \n",
        "    #Creating folder where EMNIST data is saved. Load the EMNIST dataset.\n",
        "    try:\n",
        "        os.mkdir(\"./data\")\n",
        "        print(\"Directory data Created\")\n",
        "    except FileExistsError:\n",
        "        print(\"Directory data already exists\")\n",
        "    data_path = './data/'\n",
        "\n",
        "    if not noise:\n",
        "      # No noise is being applied to the training dataset.\n",
        "      train_dataset = torchvision.datasets.EMNIST(root=data_path, split=\"balanced\", train=True, download=True,\n",
        "                                                  transform=torchvision.transforms.Compose([\n",
        "                                                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
        "                                                    lambda img: torchvision.transforms.functional.hflip(img),\n",
        "                                                    torchvision.transforms.ToTensor(),\n",
        "                                                  ]))\n",
        "    else:\n",
        "      # Noise is being applied to the training dataset.\n",
        "      train_dataset = torchvision.datasets.EMNIST(root=data_path, split=\"balanced\", train=True, download=True,\n",
        "                                                  transform=torchvision.transforms.Compose([\n",
        "                                                    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
        "                                                    lambda img: torchvision.transforms.functional.hflip(img),\n",
        "                                                    torchvision.transforms.ToTensor(),\n",
        "                                                    noise\n",
        "                                                  ]))\n",
        "    \n",
        "    test_dataset = torchvision.datasets.EMNIST(root=data_path, split=\"balanced\", train=False, download=True,\n",
        "                                                transform=torchvision.transforms.Compose([\n",
        "                                                  lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
        "                                                  lambda img: torchvision.transforms.functional.hflip(img),\n",
        "                                                  torchvision.transforms.ToTensor(),\n",
        "                                                ]))\n",
        "    indices = list()\n",
        "    for (i, x) in enumerate(train_dataset):\n",
        "      if x[1] in desired_labels:\n",
        "        indices.append(i)\n",
        "\n",
        "    train_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
        "\n",
        "    indices = list()\n",
        "    for (i, x) in enumerate(test_dataset):\n",
        "      if x[1] in desired_labels:\n",
        "        indices.append(i)\n",
        "\n",
        "    test_dataset = torch.utils.data.Subset(test_dataset, indices)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                  shuffle=False, num_workers=4)\n",
        "    train_sample_count = dict()\n",
        "    for data in train_dataloader:\n",
        "      images, labels = data\n",
        "      for l in labels:\n",
        "        train_sample_count[l.item()] = train_sample_count.get(l.item(), 0) + 1\n",
        "\n",
        "    sample_dataset = get_sample_dataset(train_dataset, desired_labels, sample_number)\n",
        "    train_dataloader = DataLoader(sample_dataset, batch_size=batch_size,\n",
        "                                  shuffle=True, num_workers=4)\n",
        "    train_sample_count = dict()\n",
        "    for data in train_dataloader:\n",
        "      images, labels = data\n",
        "      for l in labels:\n",
        "        train_sample_count[l.item()] = train_sample_count.get(l.item(), 0) + 1\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                                 shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "    #Initialize MSE loss.\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    #Initialize Adam Optimizer.\n",
        "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-3, betas=[0.9, 0.999])\n",
        "\n",
        "    # List for saving loss and accuracy\n",
        "    train_loss_list, test_accuracy_list = [], []\n",
        "    test_num = len(test_dataset)\n",
        "\n",
        "    # Dictionaries for recording test accuracy for each letter\n",
        "    test_num_by_letter = dict()\n",
        "    test_accuracy_by_letter = dict()\n",
        "\n",
        "    for data in test_dataloader:\n",
        "      images, labels = data\n",
        "      for l in labels:\n",
        "        subset_label = desired_labels[l.item()]\n",
        "        test_num_by_letter[subset_label] = test_num_by_letter.get(subset_label, 0) + 1\n",
        "    for k,v in desired_labels.items():\n",
        "        test_accuracy_by_letter[v] = []\n",
        "\n",
        "    # Start training\n",
        "    \n",
        "    #Put the network on the device\n",
        "    network.to(device)\n",
        "    \n",
        "    #Loop for the epochs\n",
        "    # Initialize max_test_accuracy to print the confusion matrix.\n",
        "    max_test_accuracy = float('-inf')\n",
        "    for ee in range(epoch):\n",
        "        #Keep track of running loss\n",
        "        running_loss = 0.0\n",
        "        running_batch_num = 0\n",
        "        train_start = time.time()\n",
        "        \n",
        "        #Iterate over the training data in train dataloader\n",
        "        for data in train_dataloader:\n",
        "            #Retrieve the image and label from data\n",
        "            images, labels = data\n",
        "            labels = torch.tensor([desired_labels[x.item()] for x in labels])\n",
        "            #Reshape labels for MSE.\n",
        "            labels = torch.tensor([[i == x.item() for i in range(len(desired_labels.keys()))] for x in labels]).float()\n",
        "            #Put the image and labels on the device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            #Convert images to event images\n",
        "            event_images = img_2_event_img(images, device, spike_ts)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #Compute the network output for the event images\n",
        "            outputs = network.forward(event_images)\n",
        "            \n",
        "            #Compute the firing rates of the each ouput neuron for MSE\n",
        "            outputs = outputs/spike_ts\n",
        "\n",
        "            #Compute the loss using the criterion defined previously. Store in a variable called loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            #Backpropagate the loss through the network.\n",
        "            loss.backward()\n",
        "            \n",
        "            #Update the network weights by taking an optimizer 'step'. \n",
        "            optimizer.step()\n",
        "            \n",
        "            #Updating tracking variables. Nothing to do here\n",
        "            running_loss += loss.item()\n",
        "            running_batch_num += 1\n",
        "\n",
        "        train_end = time.time()\n",
        "        train_loss_list.append(running_loss / running_batch_num)\n",
        "        print(\"Epoch %d Training Loss %.4f\" % (ee, train_loss_list[-1]), end=\" \")\n",
        "        \n",
        "        #Counters to keep track of the number of correct predictions\n",
        "        test_correct_num = 0\n",
        "        test_correct_by_letter = defaultdict(int)\n",
        "        confusion_matrix = [[0 for i in range(5)] for i in range(5)]\n",
        "\n",
        "        test_start = time.time()\n",
        "        with torch.no_grad():\n",
        "            for data in test_dataloader:\n",
        "                \n",
        "                #Retrieve the image and label from test data\n",
        "                images, labels = data\n",
        "                labels = torch.tensor([desired_labels[x.item()] for x in labels])\n",
        "                \n",
        "                #Put the image and labels on the device\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                #Convert the image into event images\n",
        "                event_images = img_2_event_img(images, device, spike_ts)\n",
        "                \n",
        "                #Compute the network predictions and store in a variable called outputs\n",
        "                outputs = network.forward(event_images)\n",
        "                \n",
        "                #Get the class label as the largest activation. This is complete.\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                \n",
        "                #Compare the network predictions against the true labels and update the counter for correct predictions.\n",
        "                test_correct_num += torch.sum(torch.eq(predicted, labels).float())\n",
        "                for (i,p) in enumerate(predicted):\n",
        "                  confusion_matrix[p.item()][labels[i].item()] += 1\n",
        "                  if p.item() == labels[i].item():\n",
        "                    test_correct_by_letter[p.item()] += 1\n",
        "\n",
        "        #Updating tracking variables.\n",
        "        test_end = time.time()\n",
        "        test_accuracy_list.append(test_correct_num/test_num)\n",
        "        for k,v in desired_labels.items():\n",
        "            test_accuracy_by_letter[v].append(test_correct_by_letter[v]/test_num_by_letter[v])\n",
        "\n",
        "        print(\"Test Accuracy %.4f Training Time: %.1f Test Time: %.1f\" % (\n",
        "            test_accuracy_list[-1], train_end - train_start, test_end - test_start))\n",
        "        for k, v in desired_labels.items():\n",
        "          print(\"Test Accuracy for %.f : %.4f\" %(k, test_accuracy_by_letter[v][-1]))\n",
        "        if test_accuracy_list[-1] > max_test_accuracy and ee>=30:\n",
        "          # Update max test accuracy\n",
        "          max_test_accuracy = test_accuracy_list[-1]\n",
        "          print (f\"The confusion matrix:\\n {confusion_matrix}\")\n",
        "\n",
        "    #Return the loss and accuracies. \n",
        "    print(\"End Training\")\n",
        "    network.to('cpu')\n",
        "    return train_loss_list, test_accuracy_list, test_accuracy_by_letter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Define the device on which training will be performed\\\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Define the input dimensions in a variable\n",
        "input_dim = 784\n",
        "\n",
        "#Define the output dimensions in a variable\n",
        "output_dim = 5\n",
        "\n",
        "#Define the hidden dimension in a variable\n",
        "hidden_dim = 400\n",
        "\n",
        "#Define the convolutional layer output dimensions\n",
        "conv1_dim = 32\n",
        "conv2_dim = 64\n",
        "\n",
        "#Create a dictionary of the neuron parameters for the hidden and output layer. The keys should be 'hid_layer' and 'out_layer'.\n",
        "#The values of the dictionary is a list of the neuron parameters for each layer where the list elements are [vdecay, vth, grad_win, grad_amp]\n",
        "param_dict = {'hid_layer': [0.5, 0.5, 0.5, 1.0], 'out_layer': [0.5, 0.5, 0.5, 1.0]}\n",
        "\n",
        "#Create the SNN using the class definition in 3b and the arguments defined above\n",
        "network = WrapSNN(input_dim, output_dim, hidden_dim, conv1_dim, conv2_dim, param_dict, device)\n",
        "\n",
        "#Define snn timesteps\n",
        "spike_ts = 30\n",
        "\n",
        "#Batch size for training\n",
        "batch_size = 256\n",
        "\n",
        "#Batch size for testing\n",
        "test_batch_size = 128\n",
        "\n",
        "#Epochs\n",
        "epoch=40\n",
        "\n",
        "#Sample Number\n",
        "sample_number = 800\n",
        "#The keys of desired_labels indicate the targeted labels. The values indicate their 'new' labels in the subset.\n",
        "# a, b, d, g, and q\n",
        "desired_labels = {36: 0, 37:1, 38:2, 41: 3, 44: 4}\n",
        "\n",
        "\n",
        "# Initialize a noise variable using the classes in noise.py (i.e noise = noises.AddGaussianBlur(5, 0.2)) and pass the variable to the last argument of sbtp_snn_training to train with noise.\n",
        "train_loss_list, test_accuracy_list, test_accuracy_by_letter = stbp_snn_training(network, desired_labels, spike_ts, device, batch_size, test_batch_size, epoch, sample_number)"
      ],
      "metadata": {
        "id": "gDbF_yRTN6wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Script for plotting accuracy results.\n",
        "\n",
        "epochs = range(0,epoch)\n",
        "plt.plot(epochs, test_accuracy_by_letter[0], '-o', label='Label a')\n",
        "plt.plot(epochs, test_accuracy_by_letter[1], '-o', label='Label b')\n",
        "plt.plot(epochs, test_accuracy_by_letter[2], '-o', label='Label d')\n",
        "plt.plot(epochs, test_accuracy_by_letter[3], '-o', label='Label g')\n",
        "plt.plot(epochs, test_accuracy_by_letter[4], '-o', label='Label q')\n",
        "plt.plot(epochs, [x.item() for x in test_accuracy_list], '-o', label='Overall Accuracy')\n",
        "plt.xticks(np.arange(0, epoch, 1.0))\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
        "plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "plt.title('Testing Accuracy At Each Epoch')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BrMOfskLt6Su"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "stbp_cnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}